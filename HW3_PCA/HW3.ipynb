{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data1 = pd.read_csv('/Users/xinqu/Sandbox/CS498 Applied Machine Learning/HW/HW3/hw3-data/dataI.csv').values\n",
    "data2 = pd.read_csv('/Users/xinqu/Sandbox/CS498 Applied Machine Learning/HW/HW3/hw3-data/dataII.csv').values\n",
    "data3 = pd.read_csv('/Users/xinqu/Sandbox/CS498 Applied Machine Learning/HW/HW3/hw3-data/dataIII.csv').values\n",
    "data4 = pd.read_csv('/Users/xinqu/Sandbox/CS498 Applied Machine Learning/HW/HW3/hw3-data/dataIV.csv').values\n",
    "data5 = pd.read_csv('/Users/xinqu/Sandbox/CS498 Applied Machine Learning/HW/HW3/hw3-data/dataV.csv').values\n",
    "data6 = pd.read_csv('/Users/xinqu/Sandbox/CS498 Applied Machine Learning/HW/HW3/hw3-data/iris.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg1 = np.mean(data1, axis = 0)\n",
    "avg2 = np.mean(data2, axis = 0)\n",
    "avg3 = np.mean(data3, axis = 0)\n",
    "avg4 = np.mean(data4, axis = 0)\n",
    "avg5 = np.mean(data5, axis = 0)\n",
    "avg6 = np.mean(data6, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###rescale the data\n",
    "d1 = data1 - avg1\n",
    "d2 = data2 - avg2\n",
    "d3 = data3 - avg3\n",
    "d4 = data4 - avg4\n",
    "d5 = data5 - avg5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = [avg1, avg2, avg3, avg4, avg5]\n",
    "data = [d1, d2, d3, d4, d5]\n",
    "mse = np.zeros((5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.54247067, 0.64109318, 0.71562849, 0.90839291, 1.11565786,\n",
       "        4.54953899, 0.64864211, 0.75062113, 0.94197282, 1.11565786],\n",
       "       [4.54247067, 1.29037245, 1.96724039, 2.65084114, 3.65327973,\n",
       "        4.55747296, 1.32346215, 2.11974805, 3.02737992, 3.65327973],\n",
       "       [4.54247067, 0.79994274, 0.82808255, 0.98494977, 1.194     ,\n",
       "        4.56619867, 0.84061416, 1.2070898 , 1.27119197, 1.194     ],\n",
       "       [4.54247067, 1.91776775, 3.3317221 , 4.5482572 , 5.13926667,\n",
       "        4.919928  , 2.83567943, 4.6514345 , 4.97124727, 5.13926667],\n",
       "       [4.54247067, 0.38345031, 0.175563  , 0.14178365, 0.16083836,\n",
       "        4.54311903, 0.38461353, 0.17781528, 0.14444051, 0.16083836]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npca = PCA()\n",
    "dataset = [data1, data2, data3, data4, data5]\n",
    "for d in range(5):\n",
    "    datax = dataset[d]\n",
    "    for i in range(5):\n",
    "        #### use mean and covariance matrix of noiseless dataset\n",
    "        npca.fit(data6)\n",
    "        nl_x_hat = np.dot(npca.transform(datax)[:,:i], npca.components_[:i,:]) \n",
    "        nl_x_hat += avg6 \n",
    "        nl_mse = np.sum(np.square(np.subtract(data6, nl_x_hat))) \n",
    "        nl_mse = nl_mse/(data6.shape[0])\n",
    "        mse[d, i] = nl_mse\n",
    "    for j in range(5):\n",
    "        ###use mean and covariance matrix of noisy dataset\n",
    "        pca = PCA(n_components = j, copy=True, whiten=False, svd_solver='full', iterated_power='auto')\n",
    "        x_hat = pca.fit_transform(data[d])\n",
    "        x_hat = pca.inverse_transform(x_hat)\n",
    "        x_hat += avg[d]\n",
    "        mse_tmp = np.sum(np.square(np.subtract(x_hat, data6))) / data6.shape[0]\n",
    "        mse[d, j + 5] = mse_tmp\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mse, columns = ['0N', '1N', '2N', '3N', '4N', '0c', \n",
    "                             '1c', '2c', '3c', '4c']).to_csv('xinq2-numbers.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.62456632,  3.42605349,  0.92866838,  0.07445531],\n",
       "       [ 5.25156791,  3.68292759,  1.81672193,  0.49807561],\n",
       "       [ 3.80735855,  2.13775175,  0.95829504, -0.14748297],\n",
       "       [ 4.65951505,  2.62338583,  1.99528761,  0.38098365],\n",
       "       [ 5.0688014 ,  3.19121918,  2.0768017 ,  0.51893888]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###recoonstructuobn of Dataset I\n",
    "pca_new = PCA(n_components = 2, copy=True, whiten=False, svd_solver='full', iterated_power='auto')\n",
    "x_hat_n = pca_new.fit_transform(d1)\n",
    "x_hat_n = pca_new.inverse_transform(x_hat_n) + avg1\n",
    "x_hat_n[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_hat_n, columns = ['Sepal.Length', \n",
    "                                 'Sepal.Width', 'Petal.Length', 'Petal.Width']).to_csv('xinq2-recon.csv', \n",
    "                                                                                       index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"xinq2_HW9.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.15"},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"RCxoHI5iav8j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1210},"outputId":"ba284612-eb55-4582-897f-70264b10ba38","executionInfo":{"status":"ok","timestamp":1555103959516,"user_tz":420,"elapsed":1391,"user":{"displayName":"Xin Qu","photoUrl":"https://lh6.googleusercontent.com/-8E0ph2vwdZk/AAAAAAAAAAI/AAAAAAAAAF4/8ase7VCyR9I/s64/photo.jpg","userId":"08018131279349519543"}}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow.contrib.slim.nets\n","from tensorflow.contrib.slim import fully_connected as fc\n","\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n","num_sample = mnist.train.num_examples\n","input_dim = mnist.train.images[0].shape[0]\n","w = h = 28\n","print(num_sample, input_dim)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-2-d4b7e77ef6c5>:9: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: UserWarning: \n","This call to matplotlib.use() has no effect because the backend has already\n","been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n","or matplotlib.backends is imported for the first time.\n","\n","The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n","  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n","    \"__main__\", fname, loader, pkg_name)\n","  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n","    exec code in run_globals\n","  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n","    app.initialize(argv)\n","  File \"</usr/local/lib/python2.7/dist-packages/decorator.pyc:decorator-gen-121>\", line 2, in initialize\n","  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n","    return method(app, *args, **kwargs)\n","  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n","    self.init_gui_pylab()\n","  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n","    InteractiveShellApp.init_gui_pylab(self)\n","  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n","    r = enable(key)\n","  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n","    pt.activate_matplotlib(backend)\n","  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n","    matplotlib.pyplot.switch_backend(backend)\n","  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n","    matplotlib.use(newbackend, warn=False, force=True)\n","  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py\", line 1422, in use\n","    reload(sys.modules['matplotlib.backends'])\n","  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 17, in <module>\n","    line for line in traceback.format_stack()\n","\n","\n","  import sys\n"],"name":"stderr"},{"output_type":"stream","text":["Extracting MNIST-data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST-data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","(55000, 784)\n"],"name":"stdout"}]},{"metadata":{"id":"rki7_q5Rav8q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":190},"outputId":"e2de4f5f-e8c8-4160-dfd3-53d7003fa0f2","executionInfo":{"status":"ok","timestamp":1555104459607,"user_tz":420,"elapsed":290836,"user":{"displayName":"Xin Qu","photoUrl":"https://lh6.googleusercontent.com/-8E0ph2vwdZk/AAAAAAAAAAI/AAAAAAAAAF4/8ase7VCyR9I/s64/photo.jpg","userId":"08018131279349519543"}}},"cell_type":"code","source":["class VariantionalAutoencoder(object):\n","\n","    def __init__(self, learning_rate=1e-3, batch_size=100, n_z=10):\n","        self.learning_rate = learning_rate\n","        self.batch_size = batch_size\n","        self.n_z = n_z\n","\n","        self.build()\n","\n","        self.sess = tf.InteractiveSession()\n","        self.sess.run(tf.global_variables_initializer())\n","\n","    # Build the netowrk and the loss functions\n","    def build(self):\n","        self.x = tf.placeholder(name='x', dtype=tf.float32, shape=[None, input_dim])\n","\n","        # Encode\n","        # x -> z_mean, z_sigma -> z\n","        f1 = fc(self.x, 512, scope='enc_fc1', activation_fn=tf.nn.elu)\n","        f2 = fc(f1, 384, scope='enc_fc2', activation_fn=tf.nn.elu)\n","        f3 = fc(f2, 256, scope='enc_fc3', activation_fn=tf.nn.elu)\n","        self.z_mu = fc(f3, self.n_z, scope='enc_fc4_mu', activation_fn=None)\n","        self.z_log_sigma_sq = fc(f3, self.n_z, scope='enc_fc4_sigma', activation_fn=None)\n","        eps = tf.random_normal(shape=tf.shape(self.z_log_sigma_sq),\n","                               mean=0, stddev=1, dtype=tf.float32)\n","        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n","        # Decode\n","        # z -> x_hat\n","        g1 = fc(self.z, 256, scope='dec_fc1', activation_fn=tf.nn.elu)\n","        g2 = fc(g1, 384, scope='dec_fc2', activation_fn=tf.nn.elu)\n","        g3 = fc(g2, 512, scope='dec_fc3', activation_fn=tf.nn.elu)\n","        self.x_hat = fc(g3, input_dim, scope='dec_fc4', activation_fn=tf.sigmoid)\n","\n","        # Loss\n","        # Reconstruction loss\n","        # Minimize the cross-entropy loss\n","        # H(x, x_hat) = -\\Sigma x*log(x_hat) + (1-x)*log(1-x_hat)\n","        epsilon = 1e-10\n","        recon_loss = -tf.reduce_sum(\n","            self.x * tf.log(epsilon+self.x_hat) + (1-self.x) * tf.log(epsilon+1-self.x_hat),\n","            axis=1\n","        )\n","        self.recon_loss = tf.reduce_mean(recon_loss)\n","\n","        # Latent loss\n","        # Kullback Leibler divergence: measure the difference between two distributions\n","        # Here we measure the divergence between the latent distribution and N(0, 1)\n","        latent_loss = -0.5 * tf.reduce_sum(\n","            1 + self.z_log_sigma_sq - tf.square(self.z_mu) - tf.exp(self.z_log_sigma_sq), axis=1)\n","        self.latent_loss = tf.reduce_mean(latent_loss)\n","\n","        self.total_loss = tf.reduce_mean(recon_loss + latent_loss)\n","        self.train_op = tf.train.AdamOptimizer(\n","            learning_rate=self.learning_rate).minimize(self.total_loss)\n","        return\n","\n","    # Execute the forward and the backward pass\n","    def run_single_step(self, x):\n","        _, loss, recon_loss, latent_loss = self.sess.run(\n","            [self.train_op, self.total_loss, self.recon_loss, self.latent_loss],\n","            feed_dict={self.x: x}\n","        )\n","        return loss, recon_loss, latent_loss\n","\n","    # x -> x_hat\n","    def reconstructor(self, x):\n","        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x})\n","        return x_hat\n","\n","    # z -> x\n","    def generator(self, z):\n","        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z})\n","        return x_hat\n","\n","    # x -> z\n","    def transformer(self, x):\n","        z = self.sess.run(self.z, feed_dict={self.x: x})\n","        return z\n","\n","def trainer(learning_rate=1e-3, batch_size=100, num_epoch=75, n_z=10):\n","    model = VariantionalAutoencoder(learning_rate=learning_rate,\n","                                    batch_size=batch_size, n_z=n_z)\n","\n","    for epoch in range(num_epoch):\n","        for iter in range(num_sample // batch_size):\n","            # Obtina a batch\n","            batch = mnist.train.next_batch(batch_size)\n","            # Execute the forward and the backward pass and report computed losses\n","            loss, recon_loss, latent_loss = model.run_single_step(batch[0])\n","\n","        if epoch % 5 == 0:\n","            print('[Epoch {}] Loss: {}, Recon loss: {}, Latent loss: {}'.format(\n","                epoch, loss, recon_loss, latent_loss))\n","\n","    print('Done!')\n","    return model\n","def same(labels, digit):\n","    d = np.where(labels == digit)\n","    rand_idx = np.random.choice(d[0], 2, False)\n","    return (rand_idx[0], rand_idx[1])\n","  \n","def different(labels, digit):\n","    d = np.where(labels == digit)\n","    rand_idx1 = np.random.choice(d[0], 1, False)\n","    d = np.where(labels != digit)\n","    rand_idx2 = np.random.choice(d[0], 1, False)\n","    return (rand_idx1[0], rand_idx2[0])\n","\n","\n","# Train the model\n","\n","model = trainer(learning_rate=1e-3,  batch_size=32, num_epoch=10, n_z=5)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","[Epoch 0] Loss: 141.806121826, Recon loss: 131.406051636, Latent loss: 10.4000740051\n","[Epoch 5] Loss: 112.550796509, Recon loss: 100.552513123, Latent loss: 11.9982767105\n","Done!\n"],"name":"stdout"}]},{"metadata":{"id":"UYmOWXq3b3YW","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","from google.colab import files\n","\n","digits = np.arange(10)\n","images = mnist.test.images\n","labels = mnist.test.labels\n","\n","f, ax = plt.subplots(nrows = 10, ncols = 9, figsize = (10, 10))\n","\n","for digit in range(10):\n","    imgs = []\n","    idx1, idx2 = same(labels, digit)\n","    image1 = images[idx1]\n","    image2 = images[idx2]\n","    z1 = model.transformer(image1.reshape((1, 784)))\n","    z2 = model.transformer(image2.reshape((1, 784)))\n","    diff = z2 - z1\n","\n","    for i in range(9):\n","      imgs.append( model.generator((z1 + i/ 8 * diff)).reshape((28, 28)))\n","      ax[digit, i].axis('off')\n","      ax[digit, i].imshow(imgs[i], cmap = 'gray')\n","\n","plt.savefig('same.png')\n","files.download(\"same.png\") \n","plt.close(f)\n","\n","f, ax = plt.subplots(nrows = 10, ncols = 9, figsize = (10, 10))\n","\n","for digit in range(10):\n","    imgs = []\n","    idx1, idx2 = different(labels, digit)\n","    image1 = images[idx1]\n","    image2 = images[idx2]\n","    z1 = model.transformer(image1.reshape((1, 784)))\n","    z2 = model.transformer(image2.reshape((1, 784)))\n","    diff = z2 - z1\n","    \n","    for i in range(9):\n","      imgs.append( model.generator((z1 + i/ 8 * diff)).reshape((28, 28)))\n","      ax[digit, i].axis('off')\n","      ax[digit, i].imshow(imgs[i], cmap = 'gray')\n","    \n","plt.savefig('different.png')\n","files.download(\"different.png\") \n","plt.close(f)"],"execution_count":0,"outputs":[]}]}